{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-e760a837-af8e-4afa-894c-57bcc46add18.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"784dfb","input":"","pos":59,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"013c3c","input":"#Imports\nimport pandas as pd #working with csv file\nimport matplotlib.pyplot as plt #ploting model\nfrom sklearn.model_selection import train_test_split ","pos":9,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"503b09","input":"print(\"Variance: \",ols.score(X_test,y_test))","output":{"0":{"name":"stdout","output_type":"stream","text":"Variance:  0.852493337596542\n"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"390d4c","input":"#make a pretty regression table\nimport statsmodels.api as sm\nX2 = sm.add_constant(X)\nest = sm.OLS(Y, X2)\nest2 = est.fit()\nprint(est2.summary())","output":{"0":{"name":"stdout","output_type":"stream","text":"                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.855\nModel:                            OLS   Adj. R-squared:                  0.855\nMethod:                 Least Squares   F-statistic:                 5.904e+04\nDate:                Wed, 17 Mar 2021   Prob (F-statistic):               0.00\nTime:                        03:24:06   Log-Likelihood:                -39219.\nNo. Observations:               10000   AIC:                         7.844e+04\nDf Residuals:                    9998   BIC:                         7.846e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       -350.7372      2.111   -166.109      0.000    -354.876    -346.598\nx1             7.7173      0.032    242.975      0.000       7.655       7.780\n==============================================================================\nOmnibus:                        2.141   Durbin-Watson:                   1.677\nProb(Omnibus):                  0.343   Jarque-Bera (JB):                2.150\nSkew:                           0.036   Prob(JB):                        0.341\nKurtosis:                       2.991   Cond. No.                     1.15e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.15e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"83d35d","input":"print(\"Coefficients: \",ols.coef_)\nprint(\"Y-intercept: \",ols.intercept_)","output":{"0":{"name":"stdout","output_type":"stream","text":"Coefficients:  [7.7101523]\nY-intercept:  -350.3293696067008\n"}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"b09bd9","input":"ols.predict(X_test)","output":{"0":{"data":{"text/plain":"array([163.12927764, 148.66396807, 200.7259109 , ..., 149.43825861,\n       141.77181998, 150.62944277])"},"exec_count":13,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"2fe24c","input":"X_test","output":{"0":{"data":{"text/plain":"array([[66.59513683],\n       [64.71899885],\n       [71.47138723],\n       ...,\n       [64.81942365],\n       [63.82509328],\n       [64.9739192 ]])"},"exec_count":14,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"c14f86","input":"sns.regplot(x=\"age\",y=\"bought_insurance\",data=df,logistic=True,ci=None)\nplt.show()","output":{"0":{"data":{"image/png":"f566bfa52e53defb05ada3db0a6c703eccb5ce47","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":19,"metadata":{"image/png":{"height":261,"width":386},"needs_background":"light"},"output_type":"execute_result"}},"pos":36,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"9cc5fc","input":"data=pd.read_csv(\"weight-height.csv\")\ndata.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Height</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>73.847017</td>\n      <td>241.893563</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>68.781904</td>\n      <td>162.310473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>74.110105</td>\n      <td>212.740856</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>71.730978</td>\n      <td>220.042470</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>69.881796</td>\n      <td>206.349801</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"  Gender     Height      Weight\n0   Male  73.847017  241.893563\n1   Male  68.781904  162.310473\n2   Male  74.110105  212.740856\n3   Male  71.730978  220.042470\n4   Male  69.881796  206.349801"},"exec_count":2,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"c3bae8","input":"#explanatory variables\nX=df[['age']]\n\n#dependent variables\nY=df.bought_insurance\n\n#same 20% 80% split\nX_train, X_test, y_train, y_test = train_test_split(X,Y,train_size=0.8)","pos":33,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"91ff63","input":"#import logistic regression method\nfrom sklearn.linear_model import LogisticRegression\n\nreg=LogisticRegression()\n\n#train model so we can make predictions\nreg.fit(X_train,y_train)","output":{"0":{"data":{"text/plain":"LogisticRegression()"},"exec_count":27,"output_type":"execute_result"}},"pos":34,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"a9754e","input":"#call score method \nreg.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"1.0"},"exec_count":28,"output_type":"execute_result"}},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"e1837c","input":"#explanatory variables\nX=data.iloc[:,1:2].values\n\n#dependent variables\nY=data.iloc[:,2].values\n\n#Split data into training testing sets. test set on 20% and train on 80% of data\nX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"a645dd","input":"X_test","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    age\n24   50\n1    25\n12   27\n9    61\n10   18\n11   28"},"exec_count":34,"output_type":"execute_result"}},"pos":38,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"eb9ccd","input":"#call predict method\nreg.predict(X_test)","output":{"0":{"data":{"text/plain":"array([1, 0, 0, 1, 0, 0])"},"exec_count":35,"output_type":"execute_result"}},"pos":39,"type":"cell"}
{"cell_type":"code","exec_count":36,"id":"a38c00","input":"#call predict probability method\nreg.predict_proba(X_test)","output":{"0":{"data":{"text/plain":"array([[0.20567013, 0.79432987],\n       [0.92381252, 0.07618748],\n       [0.89912945, 0.10087055],\n       [0.04549017, 0.95450983],\n       [0.97267751, 0.02732249],\n       [0.88429302, 0.11570698]])"},"exec_count":36,"output_type":"execute_result"}},"pos":41,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"b4dc30","input":"#Imports\nimport pandas as pd #working with csv file\nimport matplotlib.pyplot as plt #ploting model\nfrom sklearn.model_selection import train_test_split \nimport seaborn as sns\n%matplotlib inline\nimport os","pos":24,"type":"cell"}
{"cell_type":"code","exec_count":41,"id":"124b09","input":"df.groupby('age').mean()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bought_insurance</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"     bought_insurance\nage                  \n18                0.0\n19                0.0\n21                0.0\n22                0.0\n23                0.0\n25                0.0\n26                0.0\n27                0.0\n28                0.0\n29                0.0\n40                1.0\n45                1.0\n46                1.0\n47                1.0\n49                1.0\n50                1.0\n52                0.0\n54                1.0\n55                0.5\n56                1.0\n58                1.0\n60                1.0\n61                1.0\n62                1.0"},"exec_count":41,"output_type":"execute_result"}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":42,"id":"fb4371","input":"import pandas as pd\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\ndf=pd.read_csv(\"HR_comma_sep.csv\")\ndf.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_montly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n      <th>Department</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>0.53</td>\n      <td>2</td>\n      <td>157</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>0.86</td>\n      <td>5</td>\n      <td>262</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>0.88</td>\n      <td>7</td>\n      <td>272</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>5</td>\n      <td>223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>0.52</td>\n      <td>2</td>\n      <td>159</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n0                0.38             0.53               2                   157   \n1                0.80             0.86               5                   262   \n2                0.11             0.88               7                   272   \n3                0.72             0.87               5                   223   \n4                0.37             0.52               2                   159   \n\n   time_spend_company  Work_accident  left  promotion_last_5years Department  \\\n0                   3              0     1                      0      sales   \n1                   6              0     1                      0      sales   \n2                   4              0     1                      0      sales   \n3                   5              0     1                      0      sales   \n4                   3              0     1                      0      sales   \n\n   salary  \n0     low  \n1  medium  \n2  medium  \n3     low  \n4     low  "},"exec_count":42,"output_type":"execute_result"}},"pos":47,"type":"cell"}
{"cell_type":"code","exec_count":43,"id":"b1282d","input":"#solution\ndf.groupby('left').mean()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_montly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>promotion_last_5years</th>\n    </tr>\n    <tr>\n      <th>left</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.666810</td>\n      <td>0.715473</td>\n      <td>3.786664</td>\n      <td>199.060203</td>\n      <td>3.380032</td>\n      <td>0.175009</td>\n      <td>0.026251</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.440098</td>\n      <td>0.718113</td>\n      <td>3.855503</td>\n      <td>207.419210</td>\n      <td>3.876505</td>\n      <td>0.047326</td>\n      <td>0.005321</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      satisfaction_level  last_evaluation  number_project  \\\nleft                                                        \n0               0.666810         0.715473        3.786664   \n1               0.440098         0.718113        3.855503   \n\n      average_montly_hours  time_spend_company  Work_accident  \\\nleft                                                            \n0               199.060203            3.380032       0.175009   \n1               207.419210            3.876505       0.047326   \n\n      promotion_last_5years  \nleft                         \n0                  0.026251  \n1                  0.005321  "},"exec_count":43,"output_type":"execute_result"}},"pos":49,"type":"cell"}
{"cell_type":"code","exec_count":48,"id":"a0668c","input":"pd.crosstab(df.salary,df.left).plot(kind='bar')\nprint(\"The salaries for those the stayed with the company are significanly higher than those who left. Therefore, this information is useful for our prediction model\")\npd.crosstab(df.Department,df.left).plot(kind='bar')\nprint(\"department is not useful for our model\")","output":{"0":{"name":"stdout","output_type":"stream","text":"The salaries for those the stayed with the company are significanly higher than those who left. Therefore, this information is useful for our prediction model\nDepartemnt is not useful for our model\n"},"1":{"data":{"image/png":"433af4b01842073728ee2a2e70ff95d6090967d7","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":48,"metadata":{"image/png":{"height":293,"width":381},"needs_background":"light"},"output_type":"execute_result"},"2":{"data":{"image/png":"605f6e373d559f1894ef33d201bf90a555b3a3f4","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":48,"metadata":{"image/png":{"height":319,"width":381},"needs_background":"light"},"output_type":"execute_result"}},"pos":53,"type":"cell"}
{"cell_type":"code","exec_count":49,"id":"43ff56","input":"newDf=df[['satisfaction_level','average_montly_hours','promotion_last_5years']]\nnewDf.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>average_montly_hours</th>\n      <th>promotion_last_5years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>157</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>262</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>272</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>223</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>159</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   satisfaction_level  average_montly_hours  promotion_last_5years\n0                0.38                   157                      0\n1                0.80                   262                      0\n2                0.11                   272                      0\n3                0.72                   223                      0\n4                0.37                   159                      0"},"exec_count":49,"output_type":"execute_result"}},"pos":55,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"2977b1","input":"df=pd.read_csv(\"insurance.csv\")\ndf.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>bought_insurance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   age  bought_insurance\n0   22                 0\n1   25                 0\n2   47                 1\n3   52                 0\n4   46                 1"},"exec_count":5,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":54,"id":"d40600","input":"#answer\n#explanatory variables\nX=newDf\n\n#dependent variables\nY=df.left\n\n#same 20% 80% split\nX_train, X_test, y_train, y_test = train_test_split(X,Y,train_size=0.8)\n\n#import logistic regression method\nfrom sklearn.linear_model import LogisticRegression\n\nreg=LogisticRegression()\n\n#train model so we can make predictions\nreg.fit(X_train,y_train)","output":{"0":{"data":{"text/plain":"LogisticRegression()"},"exec_count":54,"output_type":"execute_result"}},"pos":56,"type":"cell"}
{"cell_type":"code","exec_count":55,"id":"e7e327","input":"reg.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.7786666666666666"},"exec_count":55,"output_type":"execute_result"}},"pos":57,"type":"cell"}
{"cell_type":"code","exec_count":56,"id":"f277e1","input":"reg.predict(X_test)","output":{"0":{"data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"exec_count":56,"output_type":"execute_result"}},"pos":58,"type":"cell"}
{"cell_type":"code","exec_count":58,"id":"bc997d","input":"#display Training set with linear regression line\nplt.scatter(X_train, y_train)\nplt.plot(X_train, ols.predict(X_train),color='purple')\nplt.title('Height vs Weights (Training set)')\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.show()","output":{"0":{"data":{"image/png":"fe941a3efaa92508b0f233e93b584421f75e9429","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":58,"metadata":{"image/png":{"height":277,"width":392},"needs_background":"light"},"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":59,"id":"8d809c","input":"#display Testing set with linear regression line\nplt.scatter(X_test, y_test,)\nplt.plot(X_train, ols.predict(X_train), color = 'purple')\nplt.title('Height vs weights (Test set)')\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.show()","output":{"0":{"data":{"image/png":"f46ba666802015fbb65c1ffecafbbf76eef92bb0","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":59,"metadata":{"image/png":{"height":277,"width":392},"needs_background":"light"},"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"113a02","input":"#plot data from csv file and display\nx = df.age\ny = df.bought_insurance\nplt.scatter(x,y)\nplt.xlabel('age')\nplt.ylabel('bought_insurance')\nplt.title('Age vs Bought Insurance')","output":{"0":{"data":{"text/plain":"Text(0.5, 1.0, 'Age vs Bought Insurance')"},"exec_count":6,"output_type":"execute_result"},"1":{"data":{"image/png":"272a33b531c93215349eb4f4bcbd090ecff8f6c9","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":6,"metadata":{"image/png":{"height":277,"width":386},"needs_background":"light"},"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"542bf4","input":"#build model\nfrom sklearn.linear_model import LinearRegression\nols=LinearRegression()\nols.fit(X_train,y_train)#train model so we can make predictions","output":{"0":{"data":{"text/plain":"LinearRegression()"},"exec_count":9,"output_type":"execute_result"}},"pos":12,"scrolled":true,"type":"cell"}
{"cell_type":"markdown","id":"07b055","input":"*Logistical regression* is a technique used to solved classification problems by predicting whether something is true or false instead of a continuous value. For example, it can be used to determine whether someone is obese or not obese as in the figure below. Here we have a *Binary Classification* where there are only two categories, is Obese and not Obese. However, a classification can involve multiple categories aptly named *Multiclass Classification*. You can think of this as a model predicting whether someone will vote democratic, republican, or independent as a *Multiclass Classification* where there are 3 categories. ","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"11362d","input":"a) A $1$ in the *left* column indicates and employee that stayed and 0 otherwise. Calculate the average of all columns for those that left the company and the average of those that stayed in two separate rows.","pos":48,"type":"cell"}
{"cell_type":"markdown","id":"14f269","input":"As we can see here the model is making predictions on whether or not they will buy the insurance based on the customers age. We can also use python to show you the probability of your data being in one class versus the other. For example...","pos":40,"type":"cell"}
{"cell_type":"markdown","id":"2586a3","input":"This curve tells us the probability that a customer bought insurance based on their age. Towards to bottom left half of the curve, the probability is very low and the far right is very high. We can read the middle of the graph at age 40 have ~ $50\\%$ chance of buying life insurance based on this curve. Now lets see the model in action.","pos":37,"type":"cell"}
{"cell_type":"markdown","id":"3ea67f","input":"c) Create a bar chart using pandas crosstab method that compares employee *salary* to those and stayed and those that left. Also, determine if it is a useful factor in our model. Then create the same type of chart, but compare the *department* column instead to determine if category is useful.","pos":52,"type":"cell"}
{"cell_type":"markdown","id":"3f8433","input":"# *****************Participation Check *******************\nQuestion: Looking at the graph above, what is a good predictor of if someone will buy life insurance or not?","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"5dbc42","input":"# ***********************************************","pos":29,"type":"cell"}
{"cell_type":"markdown","id":"5e6669","input":"# Quick review of Linear Regression","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"5f7a26","input":"Sources : <br> \nscreen shots, basic concept, and R^2 - https://www.youtube.com/watch?v=xxFYro8QuXA&t=422s&ab_channel=StatQuestwithJoshStarmer <br>\npython methods - https://www.youtube.com/watch?v=zM4VZR0px8E&ab_channel=codebasics <br>\nheight weight csv - https://www.kaggle.com/sonalisingh1411/linear-regression-using-weight-height/comments,<br> \ninsurance csv - https://www.youtube.com/watch?v=zM4VZR0px8E&ab_channel=codebasics, <br> \nhr csv - https://www.kaggle.com/giripujar/hr-analytics <br>\nPretty table: https://towardsdatascience.com/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8 <br> ","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"6aba07","input":"# Introduction to Logistic Regression (Statistic Modeling/Machine Learning)\n\n### Please note: This lecture will not be recorded and made available for viewing online. If you do not wish to be recorded then this is good, you do not need to adjust your camera settings accordingly. ","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"6e3715","input":"# Finally lets look logistical regression\nNow that we have reviewed all of the cool things we can do with linear regression, lets lets build a simple regression model for a *Binary Classification* problem. We will be making a logistical regression model that predicts if a customer will by life insurance based on their age.","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"77300f","input":"Now lets look at what is possible through linear regression and take a look at the simple linear regression of a single explanatory variable. This weight-height.csv was downloaded from Kaggle at https://www.kaggle.com/sonalisingh1411/linear-regression-using-weight-height. ","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"79a864","input":"![](StatQuestLogReg.png)","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"81395a","input":"The first *Class* here is if the customer will not buy insurance and the second *Class* is if they will. So in our prediction array above, customer $24$ who is $50$ years old has a $20\\%$ probability of not buying the insurance and about $80\\%$ probability of buying it. ","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"86d171","input":"Lets separate our data into training and testing sets just like we did with our linear regression model. ","pos":32,"type":"cell"}
{"cell_type":"markdown","id":"8a1674","input":"# $R^2$ with logistical regression\nIts complicated! We were able to calculate $R^2$ for our linear regression model somewhat easily, but with a logistical regression model there are over 10 different ways of determining these values. So we will focus on a common technique for our model called *Pseudo $R^2$*. This method is similar to how we calculate it in linear regression and we do so by comparing of the sum of squares for the residuals around the best fitting line, denoted by $SS(fit)$,  to the sum of squared residuals around the worst fitting line denoted as $SS(mean)$.\n$$\nR^2=\\frac{SS(mean)-SS(fit)}{SS(mean)}\n$$\nRecall that the values are between 0 and 1. When the line fits the model perfectly, SS(fit) is zero which results in the fraction reducing to 1. With logistical regression, we compare the over all probability, denoted as $LL(overall probability)$ with the log likely-hood of the fitted line made above with our *Sigmoid function*. Thus the equations is\n$$\nR^2=\\frac{LL(overall probability)-LL(fit)}{LL(overall probability)}\n$$\n\nAgain python makes this process more manageable so lets find $R^2$.","pos":43,"type":"cell"}
{"cell_type":"markdown","id":"919c80","input":"## What we can do with Linear regression","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"9c57e2","input":"#### Excercise 2\nBelow I have created a new data frame you with relevant data and left out *salary* for simplicity purposes. Create a logistical regression model and use it to make predictions based on the test set as well as calculate the variance in the model.  ","pos":54,"type":"cell"}
{"cell_type":"markdown","id":"a231e2","input":"Lastly, we can use our model to predict $height$ given a $weight$. This is a basic technique in machine learning!","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"a2e6ad","input":"# Sigmoid activation and Probabilities\nIn logistical regression we don't fit a linear equation on our model like in linear regression. Instead we make predictions by fitting a *S* shaped curve with a the *Sigmoid Function*. \n$$\nS(z) = \\frac{1} {1 + e^{-z}}\n$$\nWhere $e=$ *Euler's number*~$2.71828$ and $z$ is our equation of a line $mx+b$. This function maps our value into a number between 0 and 1 since we are dividing by a number slightly greater than 1 so the ratio is less than 1. So this is where we get that nice S shape fit on our model. Don't worry to much about the details since we will be using libraries to handle this function. You can read more about Sigmoid activation here --> at https://en.wikipedia.org/wiki/Sigmoid_function.","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"a4b7ac","input":"# Mini- Assignment\n\n#### Excercise 1: \nBelow I have created a data frame from the csv file that you will analyze. You new job is the head of the HR department at some company and your task is to predict whether an employee will leave the company or stay working. Start by looking at the data set for any correlation that could aid us in our logistical regression model to make these prediction. ","pos":46,"type":"cell"}
{"cell_type":"markdown","id":"a9d88b","input":"Answer: Those who left the company a lower satisfaction rate that those who stayed. Also, *promotions_last_5Years* are much higher in those who stayed and employees who had a higher *average_monthly_hours* were those who left the company.","pos":51,"type":"cell"}
{"cell_type":"markdown","id":"ae67cd","input":"The total comparison to \"predicted\" vs \"reality\" gives an \"error\" for our model:\n\n![](lr3.png)","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"c11d7d","input":"Great! As probably excepted we have a variance of $1.0$ , thus our line fits the model perfectly.","pos":45,"type":"cell"}
{"cell_type":"markdown","id":"cdf83f","input":"Answer: Age","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"d218ea","input":"A good place to start is to review Linear Regression and all the different analysis tools. Recall that in Linear regression we fit a linear equation on a model of the relationship between two variables and used this line to make predictions on our data set. For example, we can relate weight to height using a linear regression model and us it to predict someone's height based on their weight. Our fitted line would take the form.\n$$\nheight=\\beta_0+\\beta_1weight\n$$\nWhere $\\beta_0$ is our y-intercept and $\\beta_1$ is our coefficient. To find the *best* choice of $\\beta_0,\\beta_1$ that *minimizes* the squared error on our data set, we build a linear regression model on our data. Using ordinary least squares regression we calculate the best-fitting line by minimizing the error from the sum of the squares from each data point. Below is the picture from lecture that helps to make this concept *click*\n","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"d89ce0","input":"We can calculate square correlation $R^2$ that measures the variance in the dependent variable caused by the independent variable. This value is always between 0 and 1 inclusive and the closer to 1 the better the fit.","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"e26467","input":"We can calculate the average of those who bought the insurance based on their age and we can see as that the average person under 40 did not purchase the insurance. Thus we can conclude the Age is a good predictor for a customer making a the purchase.","pos":30,"type":"cell"}
{"cell_type":"markdown","id":"f6d06d","input":"We can also calculate the $p-value$ to determine if $R^2$ is statistically significant. In the table below we can see that the $p-value$ reads $0.000$. Although it most likely not exactly zero, it still suggests a strong correlation between the two variables. ","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"f82ed3","input":"b) What do you notice about the *satisfaction_level* for those who stayed with the company versus those who left? Are there any other difference in row values that could be useful to note?","pos":50,"type":"cell"}
{"id":0,"time":1658425912927,"type":"user"}
{"last_load":1658425913468,"type":"file"}